{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr1y3Z8xuwKy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "-O6SDN0Nu549"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"Britannia_training.xlsx\")"
      ],
      "metadata": {
        "id": "qLYSUi33u-b0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files  # Specific to Google Colab environment\n",
        "uploaded = files.upload()      # For file upload in Colab\n",
        "\n",
        "# Read Excel data file\n",
        "df = pd.read_excel(\"Britannia_training.xlsx\")\n",
        "\n",
        "# Standardize column names to lowercase\n",
        "df.columns = df.columns.str.lower()\n",
        "print(df.columns)  # Verify column names\n",
        "\n",
        "# Machine Learning imports\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class CWRV_ML_Model:\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize ML model and scaler\"\"\"\n",
        "        self.model = DecisionTreeClassifier()  # Decision Tree classifier\n",
        "        self.scaler = StandardScaler()        # Feature scaler\n",
        "        self.feature_names = []               # Store feature names for interpretation\n",
        "\n",
        "    def create_features(self, df):\n",
        "        \"\"\"Feature engineering: Convert raw price data into technical features\"\"\"\n",
        "        features = []\n",
        "        if len(df) < 5:  # Minimum 5 candles required for 4-candle window + target\n",
        "            return pd.DataFrame(), np.array([])\n",
        "\n",
        "        # Slide 4-candle window through data\n",
        "        for i in range(len(df) - 4):\n",
        "            window = df.iloc[i:i+4]  # 4-candle window\n",
        "            next_close = df.iloc[i+4]['close']  # Target candle's close\n",
        "            current_close = df.iloc[i+3]['close']  # Last candle in window's close\n",
        "\n",
        "            # Create binary label (1 if price rises, 0 otherwise)\n",
        "            label = 1 if next_close > current_close else 0\n",
        "\n",
        "            # Feature engineering block\n",
        "            row_features = {\n",
        "                # Potential issue: These counts use window-closing prices instead of individual candle patterns\n",
        "                'buyer_count': sum(1 for c in window.itertuples() if current_close < next_close),\n",
        "                'seller_count': 4 - sum(1 for c in window.itertuples() if current_close > next_close),\n",
        "\n",
        "                # Volume trend analysis (0=down, 1=neutral, 2=up)\n",
        "                'volume_trend': self._get_volume_trend(window['volume']),\n",
        "\n",
        "                # Average price movement magnitude\n",
        "                'avg_candle_size': np.mean(np.abs(window['close'] - window['open'])),\n",
        "\n",
        "                # Wick analysis (ratio of upper wick to body size)\n",
        "                'wick_ratio': np.mean(\n",
        "                    (window['high'] - window[['close', 'open']].max(axis=1)) /\n",
        "                    (window[['close', 'open']].max(axis=1) - window[['close', 'open']].min(axis=1) + 1e-8)\n",
        "                ),\n",
        "\n",
        "                # Correlation between price changes and volume\n",
        "                'body_volume_corr': window['close'].diff().corr(\n",
        "                    pd.to_numeric(window['volume'].astype(str).replace(',', ''), errors='coerce'),\n",
        "                    min_periods=1),\n",
        "\n",
        "                # Momentum of last candle in window\n",
        "                'last_momentum': 1 if window.iloc[-1]['close'] > window.iloc[-1]['open'] else 0\n",
        "            }\n",
        "\n",
        "            # Add individual candle metrics for each of 4 candles\n",
        "            for j in range(4):\n",
        "                candle = window.iloc[j]\n",
        "                row_features.update({\n",
        "                    f'candle{j+1}_body': candle['close'] - candle['open'],        # Body size\n",
        "                    f'candle{j+1}_upper_wick': candle['high'] - max(candle['close'], candle['open']),  # Upper wick\n",
        "                    f'candle{j+1}_lower_wick': min(candle['close'], candle['open']) - candle['low']   # Lower wick\n",
        "                })\n",
        "\n",
        "            features.append((row_features, label))\n",
        "\n",
        "        # Store feature names and convert to DataFrame\n",
        "        self.feature_names = list(features[0][0].keys())\n",
        "        X = pd.DataFrame([f[0] for f in features])  # Feature matrix\n",
        "        y = np.array([f[1] for f in features])      # Target vector\n",
        "        return X, y\n",
        "\n",
        "    def _get_volume_trend(self, volumes):\n",
        "        \"\"\"Calculate volume trend direction\"\"\"\n",
        "        # Clean volume data (handle commas and missing values)\n",
        "        volumes = pd.to_numeric(\n",
        "            volumes.astype(str).str.replace(',', '', regex=True),\n",
        "            errors='coerce'\n",
        "        ).fillna(0)\n",
        "\n",
        "        diffs = volumes.diff().dropna()\n",
        "        if len(diffs) < 1:\n",
        "            return 1  # Neutral if insufficient data\n",
        "        if all(diffs > 0):\n",
        "            return 2  # Strong upward trend\n",
        "        elif all(diffs < 0):\n",
        "            return 0  # Strong downward trend\n",
        "        else:\n",
        "            return 1  # Mixed trend\n",
        "\n",
        "    def train(self, data_file):\n",
        "        \"\"\"Full training pipeline\"\"\"\n",
        "        df = pd.read_excel(data_file)\n",
        "        df.columns = df.columns.str.lower()\n",
        "        X, y = self.create_features(df)\n",
        "\n",
        "        # Data cleaning\n",
        "        X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "        y = y[X.index]  # Align labels with cleaned features\n",
        "\n",
        "        if X.empty:\n",
        "            raise ValueError(\"Not enough valid data to train the model.\")\n",
        "\n",
        "        # Preprocess and split data\n",
        "        X = self.scaler.fit_transform(X)  # Scale features\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=90)\n",
        "\n",
        "        # Model training\n",
        "        self.model.fit(X_train, y_train)\n",
        "\n",
        "        # Model evaluation\n",
        "        preds = self.model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, preds)\n",
        "        cm = confusion_matrix(y_test, preds)\n",
        "        cr = classification_report(y_test, preds, target_names=['SELL', 'BUY'])\n",
        "\n",
        "        print(f\"Model Training Complete!\\nAccuracy: {accuracy:.2%}\")\n",
        "        print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "        print(\"\\nClassification Report:\\n\", cr)\n",
        "\n",
        "        # Additional diagnostics\n",
        "        self._plot_feature_importance()\n",
        "        self._plot_confusion_matrix(y_test, preds)\n",
        "\n",
        "    def predict_next(self, recent_candles):\n",
        "        \"\"\"Make prediction for new data\"\"\"\n",
        "        df = pd.DataFrame(recent_candles)\n",
        "        df.columns = df.columns.str.lower()\n",
        "        X, _ = self.create_features(df)\n",
        "\n",
        "        if X.empty:\n",
        "            raise ValueError(\"Insufficient data. Provide at least 5 candles.\")\n",
        "\n",
        "        X = self.scaler.transform(X)\n",
        "        prediction = self.model.predict(X[-1].reshape(1, -1))[0]  # Predict last available sample\n",
        "        return \"BUY\" if prediction == 1 else \"SELL\"\n",
        "\n",
        "    # Visualization methods\n",
        "    def _plot_feature_importance(self):\n",
        "        \"\"\"Visualize feature importance from decision tree\"\"\"\n",
        "        importances = self.model.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1]\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "        plt.yticks(range(len(indices)), [self.feature_names[i] for i in indices])\n",
        "        plt.title('Feature Importance Analysis')\n",
        "        plt.xlabel('Relative Importance')\n",
        "        plt.show()\n",
        "\n",
        "    def _plot_confusion_matrix(self, y_true, y_pred):\n",
        "        \"\"\"Plot confusion matrix\"\"\"\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "        plt.title('Confusion Matrix: Actual vs Predicted')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.ylabel('True Labels')\n",
        "        plt.show()\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize and train model\n",
        "    ml_model = CWRV_ML_Model()\n",
        "    ml_model.train('Britannia_training.xlsx')\n",
        "\n",
        "    # Make prediction (example using training data)\n",
        "    prediction = ml_model.predict_next(df)\n",
        "    print(f\"\\nPredicted action: {prediction}\")\n",
        "\n",
        "    # Visualize prediction context\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df['close'], marker='o', linestyle='-', label='Price Trend')\n",
        "    plt.scatter(len(df)-1, df.iloc[-1]['close'],\n",
        "                color='red' if prediction == 'SELL' else 'green',\n",
        "                s=200, label=f'Prediction: {prediction}')\n",
        "    plt.title('Price Trend with Prediction Marker')\n",
        "    plt.xlabel('Candle Index')\n",
        "    plt.ylabel('Close Price')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4-YypN8RzYtB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}